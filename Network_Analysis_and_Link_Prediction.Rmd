---
title: "drangapu_hw4"
output:
  pdf_document: default
  html_document: default
date: "2024-04-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Homework 4

#### 1. Consider the “UKFaculty friends” network, which is available in the package “igraphdata”.**\> library(igraphdata) \> data(UKfaculty) \> ?UKfaculty Using the hierarchical random graphs functions in “igraph” perform the following tasks: (a) Focus on the “UKFaculty friends” network. Transform this network into an undirected graph using the “igraph” package.**

```{r}
#install.packages("igraph")
library(igraph)
data(UKfaculty,package="igraphdata")

UKfaculty <- upgrade_graph(UKfaculty)
print(summary(UKfaculty))
plot(UKfaculty)


print(V(UKfaculty)$name)
print(E(UKfaculty)$weight)

undir_graph<- as.undirected(UKfaculty, mode = "collapse")
print(summary(undir_graph))

```

#### (b) Create noisy datasets. Do this by deleting 8% of the edges randomly (track which ones they are). Perform MCMC for a random graph model (as in Clauset et al.) on this data followed by link-prediction. Are you able to predict the edges that you deleted?

```{r}
library(mcmc)
logi_lhd <- function(theta, data) {
    edge_probs = 1 / (1 + exp(-theta))
    log_lhd = sum(data * log(edge_probs) + (1 - data) * log(1 - edge_probs))
    return(log_lhd)
  }
mcmc_adj <- function(adj_matrix) {
  initial_theta = 0
  mcmc_results = metrop(logi_lhd, initial = initial_theta, nbatch = 10000,blen = 1, scale = 0.1, data = adj_matrix)
  return(mcmc_results$batch)
}

predict_links <- function(g, rem_edges) {
  jaccard_scores = similarity(g, method = "jaccard")
  predictions = jaccard_scores * (as.matrix(as_adjacency_matrix(g)) == 0)
  rem_edge_list = t(apply(rem_edges, 1, function(edge) {
    return(c(min(edge), max(edge)))
  }))
  
  predicted_scores = predictions[rem_edge_list]
  return(list(predictions = predicted_scores))
}

mcmc_main <- function(g, del_rate) {
    set.seed(42)
    
    num_edges <- gsize(g)
    num_rem <- round(num_edges * del_rate)
    edges_to_rem <- sample(E(g), num_rem)
    g_mod <- delete_edges(g, edges_to_rem)
    adj_matrix = as.matrix(as_adjacency_matrix(g_mod))
    mcmc_results = mcmc_adj(adj_matrix)
    link_pred = predict_links(g_mod, get.edges(g, edges_to_rem))
    
    return(list(mcmc_results = mcmc_results, link_predictions = link_pred))
}

results_8 <- mcmc_main(undir_graph, 0.08)
print(results_8)
```

**Yes, the model provides predictions on the likelihood of deleted edges existence. But the accuracy of these predictions varies with some predictions showing high confidence and others much lower. This variability can be further analyzed to determine the overall effectiveness and reliability of the model using different parameters.**

**(c) Repeat the exercise in part (a) and (b) after deleting 15%, and 40% of the edges. Comment on your findings**

```{r}
results_15 <- mcmc_main(undir_graph, 0.15)
results_40 <- mcmc_main(undir_graph, 0.40)
print(results_15)
print(results_40)

```

The deletion of 15% and 40% of edges from the network significantly impacts both MCMC convergence and link prediction accuracy. This reduction in edges impacts MCMC's ability to stabilize as shown above in increasing variance in results and indicating a loss of network connectivity. The decreased accuracy in link predictions indicates that loss of informational integrity and low predictive capabilities. These findings are indicating network's sensitivity to edge removal and also highlighting the critical role of robust connectivity in maintaining functional network properties. The robustness of network structures is crucial for ensuring stability and reliability in real world predictive applications.

#### Access the SwissBankNotes data (posted with assignment). The data consists of six variables measured on 200 old Swiss 1,000-franc bank notes. The first 100 are genuine and the second 100 are counterfeit. The six variables are length of the bank note, height of the bank note, measured on the left, height of the bank note measured on the right, distance of the inner frame to the lower border, distance of inner frame to upper border, and length of the diagonal. Carry out a PCA of the 100 genuine bank notes, of the 100 counterfeit bank notes, and all of the 200 bank notes combined. Generate some biplots (use colors for the combined PCA). Do you notice any differences in the results? Show your work, and justify the selection of Principal Components, including diagnostic plots.

```{r}
load("SwissBankNotes.rdata")
print(head(SwissBankNotes, 20))

```

```{r}
library(ggplot2)
library(factoextra)
standardize_data <- function(df) {
  as.data.frame(scale(df[, 1:6]))
}

genuine_std <- standardize_data(SwissBankNotes[1:100, ])
counterfeit_std <- standardize_data(SwissBankNotes[101:200, ])
combined_std <- standardize_data(SwissBankNotes)

pca_genuine <- prcomp(genuine_std, scale. = TRUE)
pca_counterfeit <- prcomp(counterfeit_std, scale. = TRUE)
pca_combined <- prcomp(combined_std, scale. = TRUE)

fviz_eig(pca_combined, addlabels = TRUE, ylim = c(0, 100))

fviz_pca_biplot(pca_genuine, title = "PCA - Genuine Bank Notes")
fviz_pca_biplot(pca_counterfeit, title = "PCA - Counterfeit Bank Notes")
fviz_pca_biplot(pca_combined, label = "none",habillage = c(rep(1, 100), rep(2, 100)),addEllipses = TRUE,palette = c("blue", "red"),title = "PCA - Combined Bank Notes")
print(summary(pca_combined))
```

**Scree Plot Analysis**: The scree plot shows that PC1 is approximately 49.1% of the variance, and PC2 is about 21.3%. Together, PC1 and PC2 are 70.3% of the total variance. This indicates that these two components capture a significant portion of the information contained in the original variables. In general retaining components that contribute to 70-80% of the variance can be considered for a good representation of the data.

**PCA Component**: The cumulative proportion of variance is about 84.9% with three principal components (PC1, PC2, PC3), it is a good choice to select at least three for further analysis to capture most of the data.

**PCA Biplots Analysis**:

-   **Genuine Bank Notes**: The biplot for genuine notes shows that most of the data points are clustered around the center which is indicating less variation among genuine notes with respect to the principal components. The variables length,height.left/right have longer vectors which contribute more to the variance.

-   **Counterfeit Bank Notes**: For counterfeit notes the data points are more spread out which indicates greater variability in the measurements of the counterfeit notes.

-   **Combined Bank Notes**: The combined plot shows a distinction between the two groups along the first principal component with some overlap. This suggests that PC1 is important for distinguishing between genuine and counterfeit notes.

In the combined PCA the difference between genuine and counterfeit notes becomes more clear that there are patterns that PCA can capture and that may help differentiate between the two categories.

**Justification for Selection of Principal Components**: When selecting principal components consider amount of variance. Here PC1 nad PC2 only contribute 80%. if the goal is to classify between genuine and counterfeit notes, PC1 seems to be the most informative, as shown in the combined PCA biplot. If the goal is to understand the patterns of the data we need to include more components.

**Consider the USArrests data. \> library(ISLR) \> data(USArrests) \> head(USArrests) (a) Perform hierarchical clustering with complete linkage and Euclidean distance to cluster the states’. Include an illustration of the dendrogram. How many clusters do you detect. Is this what you expected?**

Based on the below dendogram we can see 4 clusters of states. There are huge jumps between cluster represents states with similar crime stats together. To me it is not unexpected to find states that could be grouped into small number of clusters based on these features like assault, murder and rape as well as urban population percentages. clusters are interpreted as groups of states with similar crime profiles. so I thought there will be 6 clusters based on the initial data analysis but it is 4 after the dendogram. Actually to know better number of clusters we can do elbow method or silhouette Method to confirm the clusters.

```{r}
library(ISLR)
data(USArrests)
data_scaled <- scale(USArrests)
hc_complete <- hclust(dist(data_scaled),method = "complete")
par(mar = c(7, 5, 2, 2))
par(cex = 0.6)

plot(hc_complete, 
     main = "Dendrogram for Complete Linkage", 
     xlab = "States", 
     sub = "",
     hang = -1, 
     cex = 0.9
)
```

(b) **Perform hierarchical clustering using a correlation based distance and complete linkage. Include an illustration of the dendrogram. How many clusters do you detect. Is this what you expected?**

    From the dendrogram, I can observe that there are a few points where a significant gap between the clusters is visible. It suggests that the data could be reasonably grouped into either two or three clusters. The choice between these options might depend on more detailed statistical criteria. Based on this dendrogram alone, I would select three clusters, as this balances detail with simplicity. This clustering aligns with what I have expected if we assume that states may vary by crime statistics which will be a natural grouping.

```{r}
dist_cor <- as.dist(1 - cor(t(data_scaled)))
hc_cor <- hclust(dist_cor, method = "complete")
par(mar = c(7, 5, 2, 2))
par(cex = 0.6)
plot(hc_cor, main = "Dendrogram with Correlation-Based Distance",      xlab = "States", 
     sub = "",
     hang = -1, 
     cex = 0.9)
```

(c) **Fit a SOM to the data and present the results (e.g., classic visualizations). Perform hclust on the codebook vectors of the SOM. Is this what you expected? Does this result generally support your results in Part A**

    The dendrogram derived from hierarchical clustering on SOM codebook vectors reveals distinct clusters, aligning with the anticipated patterns identified in Part A. This outcome, which visually encapsulates the inherent data groupings, indicates that the SOM has effectively mapped the multidimensional dataset onto a two-dimensional representation.The correspondence between these clusters and our initial results provides a reassuring validation of our approach.

```{r}
library(kohonen)
data_scaled <- scale(USArrests)
som_grid <- somgrid(xdim = 5, ydim = 5, topo = "rectangular")
som_model <- som(data_scaled, grid = som_grid, rlen = 100, alpha = c(0.05, 0.01))
plot(som_model, type = "codes")
hc_som <- hclust(dist(som_model$codes[[1]]), method = "complete")
plot(hc_som, main = "Dendrogram of SOM Codebook Vectors", xlab = "Codebook vectors", sub = "")
```

(d) **Comment on the advantages and limitations of hierarchical clustering to SOM, and discuss when one would be preferred over the other. Comments should capture a general comparison, in addition to the comments specific to this exercise.**

-   **Hierarchical Clustering**: It is intuitive and results in a dendrogram that provides a detailed view of data mergers at different stages. it is sensitive to outliers and the results depend significantly on the choice of linkage and distance measures. It's not scalable to very large datasets.

-   **Self-Organizing Maps (SOM)**: SOM reduces dimensionality and can handle large datasets, providing interpretable map of the data. It is more complex to understand and interpret. It's also sensitive to initialization parameters and the chosen topology.

**When to Use**: Hierarchical clustering is used for exploratory data analysis when you want to understand the detailed hierarchical relationship between elements. SOM is better suited for large datasets and when you want to visualize complex multidimensional data in a simplified two-dimensional space. Generally, hierarchical clustering would be preferred when the goal is to visualize and understand the nested structure within the data or when the dataset is relatively small and interpretability is of importance. SOMs might be the method of choice for larger datasets or when the goal is to map high-dimensional data to a lower-dimensional space for visualization or as a pre-processing step for analysis. In our specific exercise, the hierarchical clustering provided clear, easy-to-understand clusters of the codebook vectors obtained from the SOM the patterns discovered during the initial data analysis in Part A. This shows how combining the methods can offer a more understanding of the dataset.
